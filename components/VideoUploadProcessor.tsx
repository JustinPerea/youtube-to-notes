'use client';

import React, { useState } from 'react';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import PresentationSlides from './PresentationSlides';
import SimplePdfDownload from './SimplePdfDownload';
import ProcessingStatusBar from './ProcessingStatusBar';
import { useSession } from 'next-auth/react';
import { extractVideoId } from '@/lib/utils/youtube';
// Simplified UI - removed complex quality indicators

interface ProcessingResult {
  title: string;
  content: string;
  template: string;
  processingMethod?: 'hybrid' | 'transcript-only' | 'video-only' | 'auto' | 'fallback';
  dataSourcesUsed?: string[];
  contentAnalysis?: {
    type: string;
    complexity: string;
    confidence: number;
    cognitiveLoad?: string;
    readabilityLevel?: string;
  };
  quality?: {
    formatCompliance: number;
    nonConversationalScore: number;
    contentAdaptation: string;
    cognitiveOptimization?: string;
  };
  verbosityVersions?: {
    brief: string;
    standard: string;
    comprehensive: string;
  };
  allVerbosityLevels?: {
    brief: string;
    standard: string;
    comprehensive: string;
  };
  transcript?: {
    fullText: string;
    cleanedText: string;
    segments: Array<{
      text: string;
      duration: number;
      offset: number;
    }>;
    metadata?: {
      videoId: string;
      hasAutoGeneratedCaptions: boolean;
      language: string;
      duration: number;
      wordCount: number;
    };
  };
  processingStats?: {
    method: 'transcript' | 'video' | 'hybrid';
    tokenUsage?: string;
    costOptimization?: string;
    apiCalls?: number;
    processingTime?: number;
    transcriptWordCount?: number;
  };
}

interface VideoUploadProcessorProps {
  videoUrl: string;
  selectedTemplate: string;
  processingMode?: 'auto' | 'hybrid' | 'transcript-only' | 'video-only';
  onProcessingComplete?: () => void;
  onClose?: () => void;
  onVideoContextUpdate?: (context: any) => void; // ChatbotVideoContext from types
  onProcessedNotesUpdate?: (notes: string) => void;
}

export function VideoUploadProcessor({ 
  videoUrl, 
  selectedTemplate,
  processingMode = 'hybrid',
  onProcessingComplete,
  onClose,
  onVideoContextUpdate,
  onProcessedNotesUpdate
}: VideoUploadProcessorProps) {
  const { data: session } = useSession();
  const [isProcessing, setIsProcessing] = useState(false);
  const [result, setResult] = useState<ProcessingResult | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [showMarkdown, setShowMarkdown] = useState(true);
  const [currentVerbosity, setCurrentVerbosity] = useState<'brief' | 'standard' | 'comprehensive'>('standard');
  const [isSavingNote, setIsSavingNote] = useState(false);
  const [saveNoteMessage, setSaveNoteMessage] = useState<string | null>(null);
  const [showTranscript, setShowTranscript] = useState(false);
  const [processingStatus, setProcessingStatus] = useState<string>('Initializing...');
  const [processingStepsList, setProcessingStepsList] = useState<string[]>([]);
  const [progress, setProgress] = useState(0);
  const [estimatedTimeRemaining, setEstimatedTimeRemaining] = useState<number | null>(null);
  const [startTime, setStartTime] = useState<number | null>(null);
  const [isGeneratingAnalysis, setIsGeneratingAnalysis] = useState(false);
  const [analysisError, setAnalysisError] = useState<string | null>(null);
  const [videoMetadata, setVideoMetadata] = useState<{
    title?: string;
    duration?: string;
    channel?: string;
    publishedAt?: string;
    description?: string;
  } | null>(null);
  const [processingSteps, setProcessingSteps] = useState({
    notes: { status: 'pending' as const },
    analysis: { status: 'pending' as const },
    chatbot: { status: 'pending' as const }
  });
  // Simplified UI - removed unused state variables

  // Helper function to update specific processing step
  const updateProcessingStep = (step: 'notes' | 'analysis' | 'chatbot', updates: { status: 'pending' | 'processing' | 'complete' | 'error', message?: string, error?: string }) => {
    setProcessingSteps(prev => ({
      ...prev,
      [step]: { ...prev[step], ...updates }
    }));
  };

  React.useEffect(() => {
    if (videoUrl && selectedTemplate) {
      handleProcess();
    }
  }, [videoUrl, selectedTemplate]);

  const addProcessingStep = (step: string, progressValue?: number) => {
    setProcessingStepsList(prev => [...prev, step]);
    setProcessingStatus(step);
    
    if (progressValue !== undefined) {
      setProgress(progressValue);
      
      // Calculate estimated time remaining
      if (startTime && progressValue > 0) {
        const elapsed = Date.now() - startTime;
        const estimated = (elapsed / progressValue) * 100 - elapsed;
        setEstimatedTimeRemaining(Math.max(0, estimated));
      }
    }
  };

  const handleProcess = async () => {
    setIsProcessing(true);
    setError(null);
    setResult(null);
    setProcessingStepsList([]);
    setProgress(0);
    setStartTime(Date.now());
    setEstimatedTimeRemaining(null);

    // Initialize processing steps
    updateProcessingStep('notes', { 
      status: 'processing'
    });

    addProcessingStep('🚀 Starting video analysis...', 2);
    addProcessingStep('🔍 Validating YouTube URL...', 5);
    addProcessingStep('📊 Extracting video metadata...', 8);
    addProcessingStep('🎬 Fetching video information...', 12);

    try {
      // Add some realistic processing steps
      await new Promise(resolve => setTimeout(resolve, 1000));
      addProcessingStep('✅ Video validated successfully', 15);
      
      // Fetch video metadata early to show user what's being processed
      try {
        addProcessingStep('📋 Loading video details...', 16);
        const metadataResponse = await fetch('/api/youtube/metadata', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            url: videoUrl.trim()
          }),
        });
        
        if (metadataResponse.ok) {
          const metadata = await metadataResponse.json();
          
          // Format duration
          const duration = metadata.durationSeconds 
            ? `${Math.floor(metadata.durationSeconds / 60)}:${(metadata.durationSeconds % 60).toString().padStart(2, '0')}`
            : 'Unknown';
            
          setVideoMetadata({
            title: metadata.title || 'Unknown Title',
            duration: duration,
            channel: metadata.channelTitle || 'Unknown Channel',
            publishedAt: metadata.publishedAt ? new Date(metadata.publishedAt).toLocaleDateString() : undefined,
            description: metadata.description?.substring(0, 200) + (metadata.description?.length > 200 ? '...' : '')
          });
          
          addProcessingStep(`📺 "${metadata.title}" by ${metadata.channelTitle}`, 17);
          addProcessingStep(`⏱️ Duration: ${duration}`, 18);
        }
      } catch (metadataError) {
        console.log('Metadata fetch failed, continuing with processing');
      }
      
      await new Promise(resolve => setTimeout(resolve, 800));
      addProcessingStep('🔄 Determining optimal processing method...', 20);
      
      await new Promise(resolve => setTimeout(resolve, 600));
      addProcessingStep('🎯 Hybrid processing mode selected', 24);
      
      await new Promise(resolve => setTimeout(resolve, 500));
      addProcessingStep('🚀 Initializing AI analysis pipeline...', 28);

      // 🚀 STEP 1: Start comprehensive processing directly
      addProcessingStep('📝 Extracting transcript data...', 30);
      
      const response = await fetch('/api/videos/process', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          videoUrl: videoUrl.trim(),
          selectedTemplate,
          processingMode
        }),
      });

      // Continue with more detailed steps during API call
      addProcessingStep('🔬 Analyzing video content...', 40);
      
      // Simulate realistic processing phases
      const processingPhases = [
        { step: '📺 Processing visual elements...', progress: 45, delay: 2000 },
        { step: '🎤 Analyzing audio content...', progress: 50, delay: 1800 },
        { step: '🧠 Running AI content analysis...', progress: 60, delay: 2500 },
        { step: '📚 Extracting key concepts...', progress: 70, delay: 2000 },
        { step: '✨ Structuring information...', progress: 80, delay: 1500 },
        { step: '🎨 Formatting notes...', progress: 85, delay: 1000 },
      ];

      // Run processing phases in parallel with API call
      const phaseInterval = setInterval(() => {
        const nextPhase = processingPhases.shift();
        if (nextPhase) {
          addProcessingStep(nextPhase.step, nextPhase.progress);
        } else {
          clearInterval(phaseInterval);
        }
      }, 2000);

      const data = await response.json();
      clearInterval(phaseInterval);

      if (!response.ok) {
        throw new Error(data.error || 'Failed to process video');
      }

      // Show completion with technical details
      addProcessingStep('📊 Processing completed successfully', 90);
      
      if (data.processingMethod) {
        addProcessingStep(`🔧 Method: ${data.processingMethod}`, 92);
      }
      
      if (data.dataSourcesUsed) {
        addProcessingStep(`📋 Sources: ${data.dataSourcesUsed.join(', ')}`, 94);
      }
      
      if (data.tokenUsage) {
        addProcessingStep(`⚡ Processed ${data.tokenUsage} tokens`, 96);
      }

      addProcessingStep('✅ Your notes are ready!', 100);

      setResult(data);
      setCurrentVerbosity('standard');
      
      // Mark notes as complete
      updateProcessingStep('notes', { 
        status: 'complete'
      });

      // Start analysis processing
      updateProcessingStep('analysis', { 
        status: 'processing'
      });
      
      // Share processed notes with chatbot
      if (onProcessedNotesUpdate && data.content) {
        onProcessedNotesUpdate(data.content);
      }
      
      // ✅ Show notes immediately to user
      onProcessingComplete?.();
      
      // 🔄 Start comprehensive analysis in background (don't await - let it run async)
      generateComprehensiveAnalysis(videoUrl).catch(err => {
        console.error('Background analysis failed:', err);
        updateProcessingStep('analysis', { 
          status: 'error',
          error: 'Enhanced analysis failed, but your notes are ready!' 
        });
      });
    } catch (err: any) {
      const errorMessage = err.message || 'Something went wrong while converting your video';
      addProcessingStep('❌ Conversion failed: ' + errorMessage);
      setError(errorMessage);
    } finally {
      setIsProcessing(false);
    }
  };


  const generateComprehensiveAnalysis = async (videoUrl: string) => {
    // Extract video ID from URL
    const videoId = extractVideoId(videoUrl);
    if (!videoId) {
      console.error('Failed to extract video ID from URL:', videoUrl);
      return;
    }

    setIsGeneratingAnalysis(true);
    setAnalysisError(null);
    
    try {
      addProcessingStep('🧠 Preparing enhanced features...', 92);
      console.log('🔍 Starting comprehensive analysis generation for video:', videoId);

      const response = await fetch('/api/videos/comprehensive-analysis', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          youtubeUrl: videoUrl,
          videoId: videoId,
          requestedTemplates: ['basic-summary', 'study-notes', 'presentation-slides']
        }),
      });

      if (response.ok) {
        const analysisResult = await response.json();
        console.log('✅ Comprehensive analysis completed successfully:', analysisResult);
        addProcessingStep('🧠 Enhanced features ready!', 98);
        
        // Mark analysis as complete
        updateProcessingStep('analysis', { 
          status: 'complete'
        });

        // Start chatbot processing
        updateProcessingStep('chatbot', { 
          status: 'processing'
        });
        
        // Fetch the full analysis data for chatbot context
        await fetchAndShareVideoContext(videoId);
        
        // Mark chatbot as ready
        updateProcessingStep('chatbot', { 
          status: 'complete'
        });
        
        addProcessingStep('✅ All done! Your notes are ready to use.', 100);
      } else {
        const errorData = await response.json();
        console.warn('⚠️ Comprehensive analysis failed:', errorData.error);
        setAnalysisError(`Analysis generation failed: ${errorData.error}`);
        
        // Mark analysis as error
        updateProcessingStep('analysis', { 
          status: 'error',
          error: errorData.error
        });
        updateProcessingStep('chatbot', { 
          status: 'error',
          error: 'Analysis required for full functionality'
        });
        
        addProcessingStep(`⚠️ Some features unavailable: ${errorData.error}`, 98);
        addProcessingStep('✅ Your notes are ready!', 100);
      }
    } catch (error: any) {
      console.warn('⚠️ Comprehensive analysis error:', error);
      setAnalysisError(error.message || 'Analysis generation failed');
      
      // Mark analysis as error
      updateProcessingStep('analysis', { 
        status: 'error',
        error: error.message || 'Unknown error'
      });
      updateProcessingStep('chatbot', { 
        status: 'error',
        error: 'Analysis required for full functionality'
      });
      
      addProcessingStep(`⚠️ Some features unavailable: ${error.message || 'Unknown error'}`, 98);
      addProcessingStep('✅ Your notes are ready!', 100);
    } finally {
      setIsGeneratingAnalysis(false);
    }
  };

  const fetchAndShareVideoContext = async (videoId: string) => {
    try {
      // Fetch the full analysis data
      const response = await fetch(`/api/videos/comprehensive-analysis?videoId=${videoId}`);
      
      if (response.ok) {
        const data = await response.json();
        const analysis = data.analysis;
        
        if (analysis && onVideoContextUpdate) {
          // Transform database analysis into ChatbotVideoContext format
          const chatbotContext = {
            videoId,
            title: result?.title || 'Processed Video',
            youtubeUrl: videoUrl,
            duration: analysis.fullTranscript?.duration || 0,
            currentlyViewingFormat: selectedTemplate,
            currentVerbosityLevel: 'standard',
            userSubscriptionTier: 'free',
            analysis: {
              difficultyLevel: analysis.difficultyLevel || 'intermediate',
              primarySubject: analysis.primarySubject || 'general',
              secondarySubjects: analysis.secondarySubjects || [],
              contentTags: analysis.contentTags || [],
              conceptMap: analysis.conceptMap || { concepts: [] },
              fullTranscript: analysis.fullTranscript || { segments: [] },
              visualAnalysis: analysis.visualAnalysis || { hasSlides: false, hasCharts: false },
              keyTimestamps: analysis.keyTimestamps || [],
              allTemplateOutputs: analysis.allTemplateOutputs || {},
              suggestedQuestions: analysis.suggestedQuestions || []
            }
          };
          
          console.log('🤖 Sharing video context with chatbot:', chatbotContext.title);
          onVideoContextUpdate(chatbotContext);
        }
      } else {
        console.warn('⚠️ Could not fetch comprehensive analysis for chatbot context');
      }
    } catch (error) {
      console.warn('⚠️ Error fetching video context for chatbot:', error);
    }
  };

  const copyToClipboard = (text: string) => {
    navigator.clipboard.writeText(text);
  };

  const saveNote = async () => {
    if (!session?.user?.id || !result) return;

    setIsSavingNote(true);
    setSaveNoteMessage(null);

    try {
      const response = await fetch('/api/notes/save', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          title: result.title,
          content: result.content,
          templateId: selectedTemplate,
          tags: ['youtube', 'ai-generated'],
          youtubeUrl: videoUrl, // Add the YouTube URL to link note to video
          verbosityVersions: result.allVerbosityLevels, // Fixed: Use allVerbosityLevels from API response
        }),
      });

      const data = await response.json();

      if (data.success) {
        setSaveNoteMessage('Note saved successfully!');
        setTimeout(() => setSaveNoteMessage(null), 3000);
      } else {
        setSaveNoteMessage(data.error || 'Failed to save note');
      }
    } catch (error) {
      setSaveNoteMessage('Failed to save note');
      console.error('Error saving note:', error);
    } finally {
      setIsSavingNote(false);
    }
  };

  const adjustVerbosity = (newVerbosity: 'brief' | 'standard' | 'comprehensive') => {
    if (!result) return;
    
    // Use the consistent allVerbosityLevels field
    const verbosityData = result.allVerbosityLevels;
    if (!verbosityData) return;
    
    setCurrentVerbosity(newVerbosity);
    
    setResult({
      ...result,
      content: verbosityData[newVerbosity]
    });
  };

  if (isProcessing) {

    return (
      <div className="fixed inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center">
        <div className="bg-[var(--card-bg)] backdrop-blur-[20px] border border-[var(--card-border)] rounded-2xl p-8 max-w-2xl mx-4">
          <div className="text-center">
            <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-[var(--accent-pink)] mx-auto mb-6"></div>
            <h3 className="text-xl font-semibold text-[var(--text-primary)] mb-2">Converting Video</h3>
            <p className="text-[var(--text-secondary)] mb-6">
Converting with Premium AI...
            </p>
            
            {/* Simplified Progress Indicator */}
            <div className="mb-6 p-4 bg-[var(--bg-primary)] rounded-lg border border-[var(--card-border)]">
              {/* Premium AI Processing Badge */}
              <div className="flex items-center justify-center mb-4">
                <span className="px-4 py-2 rounded-lg text-sm font-medium border bg-purple-500/20 border-purple-500/30 text-purple-400">
                  ⭐ Premium AI Processing
                </span>
              </div>
              
              {/* Overall Progress Bar */}
              <div className="w-full bg-[var(--card-border)] rounded-full h-3 mb-3 overflow-hidden">
                <div 
                  className="bg-gradient-to-r from-[var(--accent-pink)] to-[#FF8FB3] h-full rounded-full transition-all duration-500 ease-out"
                  style={{ width: `${progress}%` }}
                />
              </div>
              
              {/* Progress Info */}
              <div className="flex items-center justify-between text-xs">
                <span className="text-[var(--text-secondary)]">{Math.round(progress)}% complete</span>
                {estimatedTimeRemaining !== null && estimatedTimeRemaining > 0 && (
                  <span className="text-[var(--text-secondary)]">
                    ~{Math.round(estimatedTimeRemaining / 1000)}s remaining
                  </span>
                )}
              </div>
            </div>

            {/* Video Metadata Display */}
            {videoMetadata && (
              <div className="mb-4 p-4 bg-[var(--bg-secondary)] rounded-lg border border-[var(--card-border)]">
                <div className="text-left space-y-2">
                  <h4 className="text-sm font-medium text-[var(--text-primary)] mb-2">Processing Video:</h4>
                  <p className="text-sm text-[var(--text-primary)] font-medium truncate" title={videoMetadata.title}>
                    📺 {videoMetadata.title}
                  </p>
                  <div className="flex flex-wrap gap-4 text-xs text-[var(--text-secondary)]">
                    <span>⏱️ {videoMetadata.duration}</span>
                    <span>📻 {videoMetadata.channel}</span>
                    {videoMetadata.publishedAt && (
                      <span>📅 {videoMetadata.publishedAt}</span>
                    )}
                  </div>
                  {videoMetadata.description && (
                    <p className="text-xs text-[var(--text-secondary)] mt-2 leading-relaxed">
                      {videoMetadata.description}
                    </p>
                  )}
                </div>
              </div>
            )}

            {/* Simple Current Status */}
            <div className="text-center p-3 bg-[var(--accent-pink)]/10 border border-[var(--accent-pink)]/20 rounded-lg">
              <p className="text-sm text-[var(--accent-pink)] font-medium">
                {processingStatus}
              </p>
            </div>
          </div>
        </div>
      </div>
    );
  }

  if (error) {
    return (
      <div className="fixed inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center">
        <div className="bg-[var(--card-bg)] backdrop-blur-[20px] border border-[var(--card-border)] rounded-2xl p-8 max-w-md mx-4">
          <div className="text-center">
            <div className="text-4xl mb-4">❌</div>
            <h3 className="text-xl font-semibold text-[var(--text-primary)] mb-2">Conversion Failed</h3>
            <p className="text-[var(--text-secondary)] mb-4">{error}</p>
            <button
              onClick={onClose}
              className="px-6 py-2 bg-[var(--accent-pink)] text-white rounded-xl font-semibold hover:bg-[var(--accent-pink)]/90 transition-colors"
            >
              Close
            </button>
          </div>
        </div>
      </div>
    );
  }

  if (!result) return null;

  return (
    <div className="fixed inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center overflow-y-auto">
      <div className="bg-[var(--card-bg)] backdrop-blur-[20px] border border-[var(--card-border)] rounded-2xl p-6 max-w-4xl mx-4 my-4 max-h-[90vh] overflow-y-auto">
        <div className="flex items-center justify-between mb-6">
          <h3 className="text-2xl font-semibold text-[var(--text-primary)]">{result.title}</h3>
          <button
            onClick={onClose}
            className="text-[var(--text-secondary)] hover:text-[var(--text-primary)] transition-colors text-2xl"
          >
            ✕
          </button>
        </div>
        
        {result.template === 'presentation-slides' ? (
          <PresentationSlides 
            content={result.content}
            videoUrl={videoUrl}
          />
        ) : (
          <>
            <div className="bg-[var(--bg-primary)] rounded-xl p-6 max-h-96 overflow-y-auto mb-4">
              {showMarkdown ? (
                <div className="text-sm text-[var(--text-primary)] prose prose-invert prose-sm max-w-none">
                  <ReactMarkdown 
                    remarkPlugins={[remarkGfm]}
                    components={{
                      h1: ({children}) => <h1 className="text-xl font-bold text-[var(--text-primary)] mb-4">{children}</h1>,
                      h2: ({children}) => <h2 className="text-lg font-semibold text-[var(--text-primary)] mb-3">{children}</h2>,
                      h3: ({children}) => <h3 className="text-base font-semibold text-[var(--text-primary)] mb-2">{children}</h3>,
                      p: ({children}) => <p className="mb-3 text-[var(--text-primary)]">{children}</p>,
                      ul: ({children}) => <ul className="list-disc list-inside mb-3 space-y-1">{children}</ul>,
                      ol: ({children}) => <ol className="list-decimal list-inside mb-3 space-y-1">{children}</ol>,
                      li: ({children}) => <li className="ml-4">{children}</li>,
                      strong: ({children}) => <strong className="font-semibold text-[var(--text-primary)]">{children}</strong>,
                      em: ({children}) => <em className="italic">{children}</em>,
                      code: ({children}) => <code className="bg-[var(--card-border)] px-1 py-0.5 rounded text-xs">{children}</code>,
                      pre: ({children}) => <pre className="bg-[var(--card-border)] p-3 rounded-lg overflow-x-auto mb-3">{children}</pre>,
                    }}
                  >
                    {typeof result.content === 'string' ? result.content : String(result.content || '')}
                  </ReactMarkdown>
                </div>
              ) : (
                <pre className="text-sm text-[var(--text-primary)] whitespace-pre-wrap font-mono">
                  {result.content}
                </pre>
              )}
            </div>

            {/* Simple Processing Success Badge */}
            <div className="mb-4 flex justify-center">
              <div className="px-4 py-2 bg-purple-500/20 border border-purple-500/30 rounded-lg">
                <div className="flex items-center space-x-2">
                  <span className="text-purple-400">⭐</span>
                  <span className="text-sm font-medium text-purple-400">
                    Processed with Premium AI
                  </span>
                  <span className="text-purple-400">✓</span>
                </div>
              </div>
            </div>

            {/* Verbosity Controls */}
            {result.allVerbosityLevels && (
              <div className="mb-4 p-4 bg-[var(--bg-primary)] rounded-xl border border-[var(--card-border)]">
                <div className="flex items-center justify-between mb-3">
                  <span className="text-sm font-medium text-[var(--text-primary)]">Adjust Detail Level</span>
                  <span className="text-xs text-[var(--text-secondary)]">Current: {currentVerbosity}</span>
                </div>
                <div className="flex items-center space-x-3">
                  <button
                    onClick={() => adjustVerbosity('brief')}
                    disabled={currentVerbosity === 'brief'}
                    className="px-3 py-1.5 bg-red-500/20 border border-red-500/30 rounded-lg text-xs text-red-400 hover:bg-red-500/30 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200"
                  >
                    Brief
                  </button>
                  <button
                    onClick={() => adjustVerbosity('standard')}
                    disabled={currentVerbosity === 'standard'}
                    className="px-3 py-1.5 bg-yellow-500/20 border border-yellow-500/30 rounded-lg text-xs text-yellow-400 hover:bg-yellow-500/30 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200"
                  >
                    Standard ⭐
                  </button>
                  <button
                    onClick={() => adjustVerbosity('comprehensive')}
                    disabled={currentVerbosity === 'comprehensive'}
                    className="px-3 py-1.5 bg-green-500/20 border border-green-500/30 rounded-lg text-xs text-green-400 hover:bg-green-500/30 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200"
                  >
                    Comprehensive
                  </button>
                </div>
              </div>
            )}

            {/* Transcript Viewer */}
            {result.transcript && (
              <div className="mb-4 p-4 bg-[var(--bg-primary)] rounded-xl border border-[var(--card-border)]">
                <div className="flex items-center justify-between mb-3">
                  <div className="flex items-center space-x-2">
                    <span className="text-sm font-medium text-[var(--text-primary)]">Source Transcript</span>
                    <span className="px-2 py-1 bg-green-500/20 border border-green-500/30 rounded text-xs text-green-400">
                      {result.processingStats?.method === 'transcript' ? 'Used for Processing' : 'Available'}
                    </span>
                  </div>
                  <button
                    onClick={() => setShowTranscript(!showTranscript)}
                    className="text-xs text-[var(--accent-pink)] hover:text-[var(--accent-pink)]/80 transition-colors"
                  >
                    {showTranscript ? 'Hide Transcript' : 'Show Transcript'}
                  </button>
                </div>
                
                {result.transcript.metadata && (
                  <div className="flex items-center space-x-4 mb-3 text-xs text-[var(--text-secondary)]">
                    <span>📝 {result.transcript.metadata.wordCount} words</span>
                    <span>⏱️ {Math.round(result.transcript.metadata.duration)}s duration</span>
                    <span>🌐 {result.transcript.metadata.language}</span>
                  </div>
                )}

                {showTranscript && (
                  <div className="max-h-64 overflow-y-auto bg-[var(--card-bg)] rounded-lg p-4 border border-[var(--card-border)]">
                    <div className="space-y-3">
                      {result.transcript.segments && result.transcript.segments.length > 0 ? (
                        <div className="space-y-2">
                          <h4 className="text-xs font-medium text-[var(--text-primary)] mb-2">Timestamped Transcript:</h4>
                          {result.transcript.segments.map((segment, index) => {
                            const minutes = Math.floor(segment.offset / 60);
                            const seconds = Math.floor(segment.offset % 60);
                            const timestamp = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                            
                            return (
                              <div key={index} className="flex space-x-3 text-xs">
                                <span className="text-[var(--accent-pink)] font-mono min-w-[45px]">{timestamp}</span>
                                <span className="text-[var(--text-primary)]">{segment.text}</span>
                              </div>
                            );
                          })}
                        </div>
                      ) : (
                        <div>
                          <h4 className="text-xs font-medium text-[var(--text-primary)] mb-2">Full Transcript:</h4>
                          <p className="text-xs text-[var(--text-primary)] leading-relaxed">
                            {result.transcript.fullText}
                          </p>
                        </div>
                      )}
                    </div>
                  </div>
                )}
              </div>
            )}

            {/* Action Buttons */}
            <div className="flex flex-wrap items-center justify-between gap-4 text-sm">
              <div className="flex items-center gap-4">
                <button
                  onClick={() => setShowMarkdown(!showMarkdown)}
                  className="text-[var(--accent-pink)] hover:text-[var(--accent-pink)]/80 transition-colors"
                >
                  {showMarkdown ? 'Show Raw' : 'Show Preview'}
                </button>
                <button
                  onClick={() => copyToClipboard(result.content)}
                  className="text-[var(--accent-pink)] hover:text-[var(--accent-pink)]/80 transition-colors"
                >
                  Copy to Clipboard
                </button>
                {result.transcript && (
                  <button
                    onClick={() => setShowTranscript(!showTranscript)}
                    className="text-[var(--accent-pink)] hover:text-[var(--accent-pink)]/80 transition-colors"
                  >
                    {showTranscript ? 'Hide Transcript' : 'View Transcript'}
                  </button>
                )}
              </div>
              
              {/* Processing Status Bar and PDF Download Section */}
              <div className="flex flex-col lg:flex-row gap-6 items-start">
                {/* Processing Status Bar */}
                <div className="lg:flex-1">
                  <h4 className="text-sm font-semibold text-[var(--text-primary)] mb-3">
                    Processing Status
                  </h4>
                  <ProcessingStatusBar 
                    steps={processingSteps}
                    compact={false}
                  />
                </div>
                
                {/* PDF Download */}
                <div className="lg:w-64 flex flex-col justify-start">
                  <SimplePdfDownload
                    content={typeof result.content === 'string' ? result.content : String(result.content || '')}
                    title={result.title}
                    template={result.template}
                  />
                </div>
              </div>
            </div>

            {/* Save Note */}
            {session?.user?.id && (
              <div className="mt-6 flex flex-col items-center space-y-2">
                <button
                  onClick={saveNote}
                  disabled={isSavingNote}
                  className="inline-flex items-center px-6 py-3 bg-green-600 hover:bg-green-700 disabled:bg-green-600/50 text-white font-medium rounded-lg transition-colors duration-200"
                >
                  <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                  </svg>
                  {isSavingNote ? 'Saving...' : 'Save Note'}
                </button>
                {saveNoteMessage && (
                  <div className={`text-sm ${saveNoteMessage.includes('successfully') ? 'text-green-400' : 'text-red-400'}`}>
                    {saveNoteMessage}
                  </div>
                )}
              </div>
            )}
          </>
        )}
      </div>
    </div>
  );
}